{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1ea4ee5-c7eb-4371-9d95-1f758dc8d9de",
   "metadata": {},
   "source": [
    "# Question Answering\n",
    "\n",
    "Dobbiamo definire in primis ciò che è il question answering che andremo a trattare.\n",
    "Il question answering è ESTRATTIVO, ovvero che diamo un contesto e una domanda, tirando fuori dal contesto la risposta. E' diverso dal question answering generico (quello di chatGPT, insomma) che ti produce in output del testo a partire da ciò che ha appreso durante il training. Questo implica che il modello alla base non avrà un'architettura encoder-decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bed7d17-cd27-4deb-acf3-0d2870db7499",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Il dataset che useremo è lo Standford Question Answering Dataset (SQuAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c600620-7de4-4a78-a183-5f4bab618d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a228a0e-4629-4202-93b7-e116b92fcc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066deb67-be19-4ef0-9ff6-d64b85dafc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f4190066117f',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'What is in front of the Notre Dame Main Building?',\n",
       " 'answers': {'text': ['a copper statue of Christ'], 'answer_start': [188]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = raw_datasets[\"train\"][1]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795d533b-e618-4cbe-ad22-5a7acece6581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'University_of_Notre_Dame'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33659a2e-9dff-4f10-b23f-cd0622899a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e1b919a-f517-4dd9-b7d7-f9060dc8cb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example[\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a55d9e-737d-4470-9c74-10d34bc28aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in train set we don't have any chance for multiple answers or no answers\n",
    "raw_datasets[\"train\"].filter(lambda x : len(x[\"answers\"][\"text\"]) !=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "624e2e82-95ae-410b-a78a-4f99dd96cd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "  'answer_start': [177, 177, 177]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"validation\"].filter(lambda x : len(x[\"answers\"][\"text\"]) !=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1898a8-d28b-4251-ad19-e52051608768",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "La tokenizzazione è un concetto molto interessante all'interno di questo genere di task. Come modello, useremo BERT. Siccome è QA estrattivo, non abbiamo bisogno di un'architettura encoder-decoder e ci facciamo bastare una encoder-only.\n",
    "\n",
    "Il tokenizer di BERT abbiamo visto che è in grado di prendere due input (caso text entailment). Faremo una cosa simile anche qui, inserendo prima la domanda e poi il context dove è contenuta la risposta. Tuttavia, può accadere che il context sia eccessivamente lungo, così tanto da superare il limite della finestra di contesto del tokenizer di BERT.\n",
    "\n",
    "Una soluzione valida è quella di spezzare il context in diverse window. Così facendo, passiamo al modello contemporaneamente più input (question+window) e la risposta cadrà in una delle finestre.\n",
    "\n",
    "C'è un problema: cosa succede se una risposta cade a metà tra le finestre? Inizia a diventare un po' un caos, in quanto il modello avrà pezzi di risposta in input diversi e non sarà in grado di trovarla. Per questo motivo, risolviamo \"sovrapponendo\" le finestre. E lo faremo in modo che ogni finestra sia sovrapposta a quelle precedenti esattamente a metà. Questo crea ridondanza degli input ma ci assicura di trovare risposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11170e2d-a6b4-44a3-a6b0-37220e5ed32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd580e2-d0cd-4cc0-974e-34012e6e1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "604af9d4-814c-476b-be0e-bf7f49972fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ed03dff-934e-4251-8afc-6e272ea21012",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = example[\"context\"]\n",
    "question = example[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f231a21-80c0-4aeb-8c15-e07a4f9bad7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building \\' s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "186676a5-4200-4f4a-93be-58788f1f376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    truncation=\"only_second\", # Effettua troncamento solo sul context (second input) e non sulla question\n",
    "    max_length=100, # Lunghezza massima finestra \n",
    "    stride=50, # Quanto c'è di overlapping tra le finestre\n",
    "    return_overflowing_tokens=True, # Qui diciamo che ci interessano i token della parte  overlappata\n",
    "    return_offsets_mapping=True # Ci ritorna l'offset che esiste tra le windows e i tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a9555a-8e44-43e9-8332-54d3205398f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b26355-832f-4e8a-8fc2-382e625dc7a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Qui è 0 perchè le finestre appartengono tutte allo stesso\n",
    "inputs[\"overflow_to_sample_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac26e1a-20db-4de7-99b3-3de3cbd0e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:3][\"question\"],\n",
    "    raw_datasets[\"train\"][:3][\"context\"],\n",
    "    truncation=\"only_second\", # Effettua troncamento solo sul context (second input) e non sulla question\n",
    "    max_length=100, # Lunghezza massima finestra \n",
    "    stride=50, # Quanto c'è di overlapping tra le finestre\n",
    "    return_overflowing_tokens=True, # Qui diciamo che ci interessano i token della parte  overlappata\n",
    "    return_offsets_mapping=True # Ci ritorna l'offset che esiste tra le windows e i tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a1f425-617f-46b1-ad50-19615666c738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"overflow_to_sample_mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd5a9498-a39f-49b6-b090-525a781151aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building ' s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the G [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] facing it, is a copper statue of Christ with arms upraised with the legend \" Venite Ad Me Omnes \". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernade [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP] of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern [SEP]\n",
      "[CLS] What is in front of the Notre Dame Main Building? [SEP]rdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    truncation=\"only_second\", # Effettua troncamento solo sul context (second input) e non sulla question\n",
    "    max_length=100, # Lunghezza massima finestra \n",
    "    stride=50, # Quanto c'è di overlapping tra le finestre\n",
    "    return_overflowing_tokens=True, # Qui diciamo che ci interessano i token della parte  overlappata\n",
    "    return_offsets_mapping=True # Ci ritorna l'offset che esiste tra le windows e i tokens\n",
    ")\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7473c86e-7e59-493e-83eb-0396a4279e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (0, 13), (13, 15), (15, 16), (17, 20), (21, 27), (28, 31), (32, 33), (34, 42), (43, 52), (52, 53), (54, 56), (56, 58), (59, 62), (63, 67), (68, 76), (76, 77), (77, 78), (79, 83), (84, 88), (89, 91), (92, 93), (94, 100), (101, 107), (108, 110), (111, 114), (115, 121), (122, 126), (126, 127), (128, 139), (140, 142), (143, 148), (149, 151), (152, 155), (156, 160), (161, 169), (170, 173), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (174, 180), (181, 183), (183, 184), (185, 187), (188, 189), (190, 196), (197, 203), (204, 206), (207, 213), (214, 218), (219, 223), (224, 226), (226, 229), (229, 232), (233, 237), (238, 241), (242, 248), (249, 250), (250, 251), (251, 254), (254, 256), (257, 259), (260, 262), (263, 264), (264, 265), (265, 268), (268, 269), (269, 270), (271, 275), (276, 278), (279, 282), (283, 287), (288, 296), (297, 299), (300, 303), (304, 312), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (313, 315), (316, 319), (320, 326), (327, 332), (332, 333), (334, 345), (346, 352), (353, 356), (357, 358), (358, 361), (361, 365), (366, 368), (369, 372), (373, 374), (374, 377), (377, 379), (379, 380), (381, 382), (383, 389), (390, 395), (396, 398), (399, 405), (406, 409), (410, 420), (420, 421), (422, 424), (425, 427), (428, 429), (430, 437), (438, 440), (441, 444), (445, 446), (446, 449), (449, 451), (452, 454), (455, 458), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (0, 0)], [(0, 0), (0, 4), (5, 7), (8, 10), (11, 16), (17, 19), (20, 23), (24, 29), (30, 34), (35, 39), (40, 48), (48, 49), (0, 0), (458, 462), (462, 463), (464, 470), (471, 476), (477, 480), (481, 487), (488, 492), (493, 500), (500, 502), (503, 511), (512, 514), (515, 520), (521, 525), (525, 528), (528, 531), (532, 534), (534, 537), (537, 541), (542, 544), (545, 549), (549, 550), (551, 553), (554, 557), (558, 561), (562, 564), (565, 568), (569, 573), (574, 579), (580, 581), (581, 584), (585, 587), (588, 589), (590, 596), (597, 601), (602, 606), (607, 615), (616, 623), (624, 625), (626, 633), (634, 637), (638, 641), (642, 646), (647, 651), (651, 652), (652, 653), (654, 656), (657, 658), (659, 665), (665, 666), (667, 673), (674, 679), (680, 686), (687, 689), (690, 694), (694, 695), (0, 0)]]\n"
     ]
    }
   ],
   "source": [
    "# Possiamo notare una cosa: questo output è una lista di liste di tuple\n",
    "# Ad ogni indice tutto inzia sempre con la domanda, ma poi quando inizia il context il conteggio della posizione si riporta\n",
    "# esattamente alla posizione contenuta nella frase originale, non alla posizione dell'input.\n",
    "# P.s: i token speciali non hanno uno spazio, motivo per il quale si indicano con (0,0)\n",
    "print(inputs[\"offset_mapping\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fab21-24f8-44ae-a7e2-4cb61f356b72",
   "metadata": {},
   "source": [
    "### Allineamento dei target\n",
    "\n",
    "Dobbiamo allineare i target, ora. Questo perchè la posizione dell'answer varia da window a window, adesso. Dobbiamo prendere la posizione assoluta dell'answer e sottrarre l'offset della window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b6b78bb-b9cd-44f1-a49c-a072d00c987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c8a95ef-6ce8-4777-93df-460735e883c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None] 100\n"
     ]
    }
   ],
   "source": [
    "# Questa funzione (sequence_ids) prende in input un indice (indice della lista esterna) e restituisce gli id.\n",
    "# Dove troviamo 0, c'è la question. Dove c'è 1, sta la window di contesto. Altrimenti sono token speciali.\n",
    "# Se usassimo BERT, potremmo avere questi campi direttamente nel \"token_type_id\"\n",
    "print(inputs.sequence_ids(0), len(inputs.sequence_ids(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1094ab2-11dc-47b5-813f-084444109c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['a copper statue of Christ'], 'answer_start': [188]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quel è il problema? Che dividendo la finestra di contesto, la posizione della risposta parte a 181.\n",
    "# Questo significa che la risposta è presente sia nella finestra 100-200 che in quella 150 2500.\n",
    "# nel primo caso la lunghezza relativa è 81, nel secondo 31\n",
    "answer = raw_datasets[\"train\"][1][\"answers\"]\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f542704a-6ee5-44c0-a3bf-d9e6731da2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Il tipo è una lista\n",
    "type(inputs.sequence_ids(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62057a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_ids = inputs.sequence_ids(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91cc93e2-a411-490b-bde1-c5d3eb917213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prima occorrenza di 1\n",
    "sequence_ids.index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bef00959-ea9c-432d-b613-28afd588ad5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 98)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invertiamo i sequence ids e vediamo dove si trova l'1 ora:\n",
    "# Siccome l'ultimo token è il SEP, avremo ovviamente che la stringa al contrario è il primo.\n",
    "# Usiamo questa informazione per tagliare, dalla lunghezza massima, il valore di indice\n",
    "sequence_ids[::-1].index(1), len(sequence_ids) - sequence_ids[::-1].index(1) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b70a7bb8-2d85-4e53-a576-bca5350ab4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13], dtype=int64), array([98], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in alternativa...\n",
    "np.argwhere(sequence_ids)[0], np.argwhere(sequence_ids)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a950c76-e38d-4ec6-9daf-1ef649b2ea43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 98)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ora vogliamo usare questa funzione in combinazione con gli ids per trovare il context:\n",
    "sequence_ids = inputs.sequence_ids(0)\n",
    "ctx_start = sequence_ids.index(1) # -> Ci dice l'indice della prima occorrenza dell'1\n",
    "ctx_end = len(sequence_ids) - sequence_ids[::-1].index(1) -1\n",
    "\n",
    "ctx_start, ctx_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce0be9fe-ee5f-4f2f-b4df-c52105cc5cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 57)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ora arriviamo a trovare la posizione della risposta nelle finestre di contesto, a partire dall'indice della risposta nella\n",
    "# lista. quindi mapperemo la risposta da \"char index\" a \"token index\" e poi da \"token index (full context) a \"window token idx\".\n",
    "# Se non è presente nella finestra, usremo (0,0) come coordinata del token [spazio nullo]\n",
    "# Faremo questa cosa staticamente per solo la prima finestra. Poi inseriremo tutto in un loop\n",
    "ans_start_char = answer[\"answer_start\"][0] #188\n",
    "ans_end_char = ans_start_char + len(answer[\"text\"][0]) #188+ len\n",
    "\n",
    "offset = inputs[\"offset_mapping\"][0]\n",
    "start_idx, end_idx = 0, 0\n",
    "# RICORDA: Offset = tupla (x, y) dove il primo valore (x) è l'indice di partenza del token, y è l'indice di arrivo\n",
    "# Se il primo valore di offset della prima parola è maggiore dell'indice di inizio della risposta \n",
    "# OPPURE se l'ultimo valore di offset dell'ultima parola è minore dell'indice di fine della risposta\n",
    "if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
    "    print(\"(0, 0)\") # Fai nulla\n",
    "else:\n",
    "    # Troviamo la posizione relativa della rispsota nella finestra di contesto.\n",
    "    # Loopiamo negli offset, cerchiamo linearmente i token all'interno della tupla\n",
    "    i = ctx_start # Partiamo da qui per evitare di trovare la posizione nella domanda.\n",
    "    for start_end_char in offset[ctx_start:]:\n",
    "        start, end = start_end_char\n",
    "        if start == ans_start_char:\n",
    "            start_idx = i\n",
    "        if end == ans_end_char:\n",
    "            end_idx = i\n",
    "            break # il break solo qui\n",
    "        i+=1\n",
    "\n",
    "start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ea1b8d4-4c8e-439f-b330-4ca10f9b26c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([170, 7335, 5921, 1104, 4028], 'a copper statue of Christ')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vediamo se è corretto:\n",
    "input_ids = inputs[\"input_ids\"][0]\n",
    "input_ids[start_idx:end_idx+1] , tokenizer.decode(input_ids[start_idx:end_idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed8adcbe-0b8f-485f-9905-cff1906e2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scriviamoci la funzione\n",
    "def find_answer_token_idx(ctx_start, ctx_end, ans_start_char, ans_end_char, offset):\n",
    "    start_idx, end_idx = 0, 0\n",
    "    #Se la risposta non è interamente contenuta nel context:\n",
    "    if offset[ctx_start][0] > ans_start_char or offset[ctx_end][1] < ans_end_char:\n",
    "        pass\n",
    "        # Ritorna 0, 0 come settato all'inizio\n",
    "    else:\n",
    "        i = ctx_start\n",
    "        for start_end_char in offset[ctx_start:]:\n",
    "            start, end = start_end_char\n",
    "            if start == ans_start_char:\n",
    "                start_idx = i\n",
    "            if end == ans_end_char:\n",
    "                end_idx = i\n",
    "                break # il break solo qui\n",
    "            i+=1\n",
    "    \n",
    "    return start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd25db98-38e5-4fb5-be24-7983a1c98fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([53, 17, 0, 0], [57, 21, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mettiamo tutto in un loop per tutte le finestre di contesto, usando questa funzione!\n",
    "\n",
    "start_idxs, end_idxs = [], []\n",
    "for i, offset in enumerate(inputs['offset_mapping']):\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "    context_ids = np.argwhere(sequence_ids)\n",
    "    ctx_start, ctx_end = context_ids[0][0], int(context_ids[-1][0])\n",
    "\n",
    "    start_idx, end_idx = find_answer_token_idx(ctx_start, ctx_end, ans_start_char, ans_end_char, offset)\n",
    "    start_idxs.append(start_idx)\n",
    "    end_idxs.append(end_idx)\n",
    "\n",
    "start_idxs, end_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a8fea-eb5b-4538-b23d-b0d67ef416d7",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "A differenza del solito, questa volta i tokenizer saranno due. Uno in fase di training, uno in fase di evaluating.\n",
    "Key points:\n",
    "1. Dobbiamo creare le context window\n",
    "2. Siccome molti dati raggiungeranno la max length, il padding lo inseriamo nel tokenizer e sarà uguale per tutti\n",
    "3. Dobbiamo allineare le answer alle context window\n",
    "\n",
    "Il motivo dei due tokenizer è perchè facciamo operazioni diverse sugli output. Nel tokenizer di validazione, infatti, le metriche lavoreranno direttamente sulle stringhe, non sugli IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e828488-57f2-4786-bf57-926c52d31e3b",
   "metadata": {},
   "source": [
    "### Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c33365d-8fd8-4acd-9854-9639a30800a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In what city and state did Beyonce  grow up? \n",
      " The album, Dangerously in Love  achieved what spot on the Billboard Top 100 chart?\n",
      "Which song did Beyonce sing at the first couple's inaugural ball? \n",
      "What event did Beyoncé perform at one month after Obama's inauguration? \n",
      "Where was the album released? \n",
      "What movie influenced Beyonce towards empowerment themes? \n"
     ]
    }
   ],
   "source": [
    "# In primo luogo, alcune domande sono mal formattate ed hanno degli spazi prima e dopo. Vediamo quali:\n",
    "for q in raw_datasets[\"train\"][\"question\"][:1000]:\n",
    "    if q.strip() != q:\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcaee061-db5f-48f7-87bf-928e17eb61ab",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Questi valori vengono da esperimenti di google:\n",
    "max_lenght = 384\n",
    "stride = 128\n",
    "\n",
    "def tokenizer_fn_train(batch):\n",
    "\n",
    "    questions = [q.strip() for q in batch[\"question\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        batch[\"context\"],\n",
    "        max_length=max_lenght,\n",
    "        stride=stride,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Siccome non avremo bisogno delle colonne dopo, le rimuoviamo per non ritrovarcele in uscita\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = batch[\"answers\"]\n",
    "\n",
    "    start_idxs, end_idxs = [], []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        # Qui noi stiamo semplicemente recuperando la risposta dal dataset originale (raw) perchè il tokenizer crea quello espanso\n",
    "        sample_idx = orig_sample_idxs[i]\n",
    "        answer = answers[sample_idx]\n",
    "        \n",
    "        ans_start_char = answer[\"answer_start\"][0]\n",
    "        ans_end_char = ans_start_char + len(answer[\"text\"][0])\n",
    "        \n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        context_ids = np.argwhere(sequence_ids)\n",
    "        ctx_start, ctx_end = context_ids[0][0], int(context_ids[-1][0])\n",
    "\n",
    "        start_idx, end_idx = find_answer_token_idx(ctx_start, ctx_end, ans_start_char, ans_end_char, offset)\n",
    "        start_idxs.append(start_idx)\n",
    "        end_idxs.append(end_idx)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_idxs\n",
    "    inputs[\"end_positions\"] = end_idxs\n",
    "    return inputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43509283-cbf5-43fc-b8e4-0e1c04d23380",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(tokenizer_fn_train, batched=True, remove_columns=raw_datasets[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e671fb-99dc-4b7b-862e-e4dacfb9fd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 88729)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f9373-1890-414a-ae77-eecc862afc09",
   "metadata": {},
   "source": [
    "### Eval Tokenizer\n",
    "\n",
    "Il tokenizer della validazione non necessita dei target. La risposta sarò comparata direttamente sulle stringhe\n",
    "\n",
    "Una seconda differenza riguarda l'offset mapping: metteremo a \"None\" i token relativi alla domanda, scopriremo perchè dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df66daf1-e391-46d5-9a78-239c12402915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "  'answer_start': [177, 177, 177]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Terremo gli \"id\", gli identificatori univoci del campione nel dato. Serviranno per matchare correttamente in fase di eval\n",
    "raw_datasets[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5e05cd8-9673-46b4-9e21-aebccee3a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_fn_validation(batch):\n",
    "\n",
    "    questions = [q.strip() for q in batch[\"question\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        batch[\"context\"],\n",
    "        max_length=max_lenght,\n",
    "        stride=stride,\n",
    "        truncation=\"only_second\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    # Siccome non avremo bisogno delle colonne dopo, le rimuoviamo per non ritrovarcele in uscita\n",
    "    orig_sample_idxs = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    sample_ids = [] # Qui ci saranno gli id alfanumerici\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = orig_sample_idxs[i]\n",
    "        sample_ids.append(batch[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "\n",
    "        # Lascia l'offset invariato se è relativo al contesto, altrimenti diventa un None\n",
    "        inputs[\"offset_mapping\"][i] = [x if sequence_ids[j] == 1 else None for j, x  in enumerate(offset)]\n",
    "\n",
    "    inputs[\"sample_id\"] = sample_ids\n",
    "\n",
    "    return inputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cd645db-0444-4179-8526-6acd2a1f15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    tokenizer_fn_validation, batched=True, remove_columns=raw_datasets[\"validation\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "694ee654-f115-47af-ae14-b4d4543708d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10570, 10822)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_datasets[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4bce7",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "A differenza di altre metriche, qui non andiamo a comparare la posizione dei token a livello quantitativo. La metrica che andremo ad usare è una metrica legata al dataset e fa il confronto tra la risposta ottenuta e la risposta reale.\n",
    "Questo significa che dovremo convertire le risposte del modello in stringhe.\n",
    "\n",
    "Altra cosa importante è cosa restituisce la metrica. Ci da due valori: il primo è un exact matching (#chars predetti bene / #total chars), l'altra è una metrica più smooth che ammette a risposte vicine a quelle sbagliate di avere un bonus.\n",
    "\n",
    "La metrica si aspetta due input: una list di dizionari come predizioni e una lista di dizionari per le references. Queste due però sono diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b9b86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4712a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "578f2624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 66.66666666666667, 'f1': 83.33333333333333}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answers = [\n",
    "    {'id': '1', 'prediction_text': 'Albert Einstein'},\n",
    "    {'id': '2', 'prediction_text': 'physicist'},\n",
    "    {'id': '3', 'prediction_text': 'general relativity'}\n",
    "]\n",
    "\n",
    "true_answers = [\n",
    "    {'id': '1', 'answers': {'text': ['Albert Einstein'], 'answer_start':[100]}},\n",
    "    {'id': '2', 'answers': {'text': ['physicist'], 'answer_start':[100]}},\n",
    "    {'id': '3', 'answers': {'text': ['special relativity'], 'answer_start':[100]}}\n",
    "]\n",
    "    \n",
    "metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45038a",
   "metadata": {},
   "source": [
    "### Conversione Logit -> Stringhe\n",
    "\n",
    "Attualmente stiamo creando la funzione per convertire i logit in stringhe. In particolare creiamo proprio la \"compute_metrics\". Per testarla, proviamo un modello già addestrato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f7e35cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9768b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_validation_dataset = raw_datasets[\"validation\"].select(range(100))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7576234f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Facciamo sto switch perchè il tokenizer si riferisce ad una global variable chiamata \"tokenizer\"\n",
    "old_tokenizer = tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "859c7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_validation_processed = small_validation_dataset.map(\n",
    "    tokenizer_fn_validation,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names\n",
    ")\n",
    "    \n",
    "tokenizer = old_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3c066a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portiamo in torch\n",
    "small_model_inputs = small_validation_processed.remove_columns([\"sample_id\", \"offset_mapping\"])\n",
    "small_model_inputs.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69a0c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portiamo in GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "small_model_inputs_gpu = {\n",
    "    k: small_model_inputs[k].to(device) for k in small_model_inputs.column_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6bdb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scarichiamo il modello\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1a5d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  5979,  4279,  ...,     0,     0,     0],\n",
      "        [  101,  5979,  4279,  ...,     0,     0,     0],\n",
      "        [  101,  2777,  1225,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  1327,  1160,  ...,     0,     0,     0],\n",
      "        [  101,  2627,  3012,  ...,     0,     0,     0],\n",
      "        [  101,  2627, 21188,  ...,     0,     0,     0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(small_model_inputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e57256bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otteniamo gli output senza aggiornare il modello\n",
    "# Il doppio asterisco converte il dizionario small_model_inputs_gpu negli argomenti del modello\n",
    "# E' come se facesse trained_model(input_ids=x, attentiona_mask=y)\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**small_model_inputs_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1eb7ec27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ -2.2607,  -5.1783,  -5.2709,  ...,  -9.5243,  -9.5183,  -9.5288],\n",
       "        [ -2.5961,  -5.5482,  -5.5313,  ...,  -9.9598,  -9.9533,  -9.9860],\n",
       "        [ -3.7127,  -7.1848,  -8.5388,  ..., -11.6557, -11.6571, -11.6505],\n",
       "        ...,\n",
       "        [ -2.0260,  -4.4167,  -4.4980,  ...,  -8.1479,  -8.1530,  -8.1760],\n",
       "        [ -4.1553,  -5.8304,  -7.1643,  ..., -10.5255, -10.5251, -10.4890],\n",
       "        [ -3.2000,  -5.8162,  -6.7249,  ...,  -9.4935,  -9.5038,  -9.4871]],\n",
       "       device='cuda:0'), end_logits=tensor([[ -0.7353,  -4.9236,  -5.1048,  ...,  -8.8734,  -8.8916,  -8.8550],\n",
       "        [ -1.3056,  -5.3870,  -5.4945,  ...,  -9.4895,  -9.5039,  -9.4958],\n",
       "        [ -2.7649,  -7.2201,  -9.0916,  ..., -11.3106, -11.3414, -11.2702],\n",
       "        ...,\n",
       "        [ -0.0768,  -4.8210,  -4.4374,  ...,  -8.0483,  -8.0502,  -7.9903],\n",
       "        [ -2.7347,  -5.3650,  -7.2549,  ..., -10.0498, -10.0661,  -9.9886],\n",
       "        [ -1.0991,  -4.2569,  -6.1267,  ...,  -8.6882,  -8.6889,  -8.6272]],\n",
       "       device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L'oggetto è particolare\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6753839",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0208a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['56be4db0acb8001400a502ec', '56be4db0acb8001400a502ed', '56be4db0acb8001400a502ee', '56be4db0acb8001400a502ef', '56be4db0acb8001400a502f0']\n",
      "10822\n",
      "10570\n"
     ]
    }
   ],
   "source": [
    "# Ora vediamo la questione dei samples.\n",
    "# Gli id sono delle stringhe alfanumeriche. Alcune di queste si ripetono nel dataset\n",
    "print(small_validation_processed[\"sample_id\"][:5])\n",
    "print(len(validation_dataset[\"sample_id\"]))\n",
    "print(len(set(validation_dataset[\"sample_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73c4419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un mapping \"string\": numero campioni\n",
    "sample_id2idxs = {}\n",
    "for i, id_ in enumerate(small_validation_processed[\"sample_id\"]):\n",
    "    if id_ not in sample_id2idxs:\n",
    "        sample_id2idxs[id_] = [i]\n",
    "    else:\n",
    "        sample_id2idxs[id_].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58994670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 384), (100, 384))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits.shape, end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f38caea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.694445  ,  9.803685  ,  4.459973  ,  4.400487  ,  2.9437785 ,\n",
       "        2.7017367 ,  2.0126448 ,  1.5780739 ,  0.52237445,  0.02073721,\n",
       "       -0.02802688, -0.04971648, -0.38573122, -0.6945363 , -0.7979508 ,\n",
       "       -0.86780477, -0.87220925, -1.3516886 , -1.3703715 , -1.3878827 ,\n",
       "       -1.5135094 , -1.7355472 , -1.8827027 , -1.8932863 , -1.9078972 ,\n",
       "       -1.9304978 , -2.2607322 , -2.2983866 , -2.3069332 , -2.5027428 ,\n",
       "       -2.510063  , -2.530842  , -2.5399983 , -2.6718144 , -2.732354  ,\n",
       "       -2.7710216 , -2.7713673 , -2.9521358 , -3.0604653 , -3.1706066 ,\n",
       "       -3.204542  , -3.569336  , -3.5798059 , -3.6668851 , -3.7250628 ,\n",
       "       -3.7498565 , -3.7632205 , -3.996814  , -4.0113316 , -4.0688004 ,\n",
       "       -4.0944853 , -4.195475  , -4.2383103 , -4.3323617 , -4.352419  ,\n",
       "       -4.3879614 , -4.38861   , -4.396615  , -4.6790547 , -4.7030315 ,\n",
       "       -4.7757587 , -4.7778134 , -4.788218  , -4.7882495 , -4.8221273 ,\n",
       "       -4.872539  , -4.8849363 , -4.8981495 , -5.072096  , -5.10788   ,\n",
       "       -5.1486406 , -5.178329  , -5.191211  , -5.2709002 , -5.3146424 ,\n",
       "       -5.3770766 , -5.5316567 , -5.571128  , -5.6498227 , -5.661312  ,\n",
       "       -5.6778703 , -5.6986046 , -5.751567  , -5.842644  , -5.8621545 ,\n",
       "       -5.9076943 , -5.9093847 , -5.9444485 , -5.996893  , -6.005829  ,\n",
       "       -6.047037  , -6.0640035 , -6.085876  , -6.1005545 , -6.224175  ,\n",
       "       -6.2670965 , -6.2752924 , -6.3032937 , -6.31342   , -6.328805  ,\n",
       "       -6.3306923 , -6.4014874 , -6.4204855 , -6.4361095 , -6.437409  ,\n",
       "       -6.450712  , -6.53143   , -6.5530505 , -6.563022  , -6.668796  ,\n",
       "       -6.7266903 , -6.742629  , -6.744297  , -6.745856  , -6.8108754 ,\n",
       "       -6.921636  , -6.949301  , -6.990772  , -6.9987435 , -7.162264  ,\n",
       "       -7.167353  , -7.1756635 , -7.180565  , -7.1967816 , -7.243593  ,\n",
       "       -7.2733436 , -7.2769523 , -7.3002205 , -7.300931  , -7.3218613 ,\n",
       "       -7.3976803 , -7.4330378 , -7.524845  , -7.5272303 , -7.5322757 ,\n",
       "       -7.573714  , -7.5982127 , -7.658098  , -7.6597095 , -7.7155743 ,\n",
       "       -7.718405  , -7.7400193 , -7.7546544 , -7.885649  , -7.8937654 ,\n",
       "       -7.894368  , -7.938035  , -7.958206  , -8.037518  , -8.059216  ,\n",
       "       -8.063911  , -8.104637  , -8.117334  , -8.138481  , -8.145774  ,\n",
       "       -8.221222  , -8.274247  , -8.292227  , -8.293207  , -8.316828  ,\n",
       "       -8.317498  , -8.334003  , -8.46651   , -8.500584  , -8.502033  ,\n",
       "       -8.591039  , -8.612478  , -8.621495  , -8.6252165 , -8.62546   ,\n",
       "       -8.814265  , -9.039057  , -9.421061  , -9.434792  , -9.4414625 ,\n",
       "       -9.444372  , -9.449848  , -9.450177  , -9.450438  , -9.451044  ,\n",
       "       -9.452064  , -9.452417  , -9.452519  , -9.454133  , -9.456526  ,\n",
       "       -9.458107  , -9.458341  , -9.458446  , -9.458754  , -9.460873  ,\n",
       "       -9.462076  , -9.462511  , -9.462944  , -9.463792  , -9.463905  ,\n",
       "       -9.465524  , -9.466457  , -9.468561  , -9.468853  , -9.468954  ,\n",
       "       -9.469498  , -9.469519  , -9.470058  , -9.470969  , -9.471138  ,\n",
       "       -9.471284  , -9.47136   , -9.471792  , -9.471888  , -9.472047  ,\n",
       "       -9.472694  , -9.472961  , -9.47371   , -9.475201  , -9.4766035 ,\n",
       "       -9.476761  , -9.476779  , -9.4774065 , -9.478309  , -9.478877  ,\n",
       "       -9.479751  , -9.479915  , -9.480066  , -9.480646  , -9.481189  ,\n",
       "       -9.481474  , -9.48152   , -9.481533  , -9.481612  , -9.48179   ,\n",
       "       -9.482165  , -9.482849  , -9.483409  , -9.484575  , -9.484707  ,\n",
       "       -9.484897  , -9.485176  , -9.485302  , -9.485718  , -9.48596   ,\n",
       "       -9.486807  , -9.486976  , -9.487629  , -9.487733  , -9.487908  ,\n",
       "       -9.487989  , -9.488306  , -9.488396  , -9.48859   , -9.488794  ,\n",
       "       -9.488956  , -9.489108  , -9.489487  , -9.489674  , -9.490006  ,\n",
       "       -9.490808  , -9.490833  , -9.490876  , -9.4909    , -9.491136  ,\n",
       "       -9.491258  , -9.49171   , -9.49203   , -9.492166  , -9.492534  ,\n",
       "       -9.492819  , -9.493566  , -9.493645  , -9.493655  , -9.494009  ,\n",
       "       -9.494032  , -9.494384  , -9.495204  , -9.495423  , -9.496533  ,\n",
       "       -9.496601  , -9.497125  , -9.49753   , -9.4975605 , -9.49757   ,\n",
       "       -9.497612  , -9.497622  , -9.498015  , -9.498126  , -9.498631  ,\n",
       "       -9.498655  , -9.498768  , -9.499587  , -9.500014  , -9.500341  ,\n",
       "       -9.50042   , -9.500582  , -9.5009775 , -9.500998  , -9.50117   ,\n",
       "       -9.501225  , -9.501287  , -9.501437  , -9.501509  , -9.501883  ,\n",
       "       -9.502013  , -9.502524  , -9.502687  , -9.503571  , -9.503639  ,\n",
       "       -9.503665  , -9.504168  , -9.504552  , -9.505051  , -9.505538  ,\n",
       "       -9.506176  , -9.506638  , -9.5066805 , -9.506758  , -9.506831  ,\n",
       "       -9.507124  , -9.507556  , -9.5077305 , -9.507984  , -9.508048  ,\n",
       "       -9.508078  , -9.508736  , -9.508773  , -9.50886   , -9.509268  ,\n",
       "       -9.509509  , -9.509532  , -9.510821  , -9.511501  , -9.512038  ,\n",
       "       -9.512431  , -9.512821  , -9.513132  , -9.513145  , -9.513196  ,\n",
       "       -9.513245  , -9.513383  , -9.514933  , -9.5154295 , -9.515567  ,\n",
       "       -9.516188  , -9.516245  , -9.516346  , -9.51638   , -9.516658  ,\n",
       "       -9.517014  , -9.518301  , -9.518472  , -9.518793  , -9.519091  ,\n",
       "       -9.520803  , -9.521007  , -9.521188  , -9.52123   , -9.522545  ,\n",
       "       -9.522749  , -9.522892  , -9.523227  , -9.523898  , -9.524339  ,\n",
       "       -9.525378  , -9.526041  , -9.52703   , -9.528465  , -9.528533  ,\n",
       "       -9.528625  , -9.528757  , -9.529464  , -9.529711  , -9.531369  ,\n",
       "       -9.532368  , -9.532749  , -9.535536  , -9.536652  , -9.537719  ,\n",
       "       -9.538665  , -9.539045  , -9.539342  , -9.540272  , -9.541709  ,\n",
       "       -9.548323  , -9.554484  , -9.557686  , -9.567405  ], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questo per ricordarci come fare un ordering discendente di qualcosa basato su indici. \n",
    "# Ci serve per trovare gli n indici dei valori più alti agilmente\n",
    "(-start_logits[0]).argsort()\n",
    "start_logits[0][(-start_logits[0]).argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef2532ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, [0, 5], [6, 10], [11, 13], [14, 17], [18, 20], [21, 29], [30, 38], [39, 43], [44, 46], [47, 56], [57, 60], [61, 69], [70, 72], [73, 76], [77, 85], [86, 94], [95, 101], [102, 103], [103, 106], [106, 107], [108, 111], [112, 115], [116, 120], [121, 127], [127, 128], [129, 132], [133, 141], [142, 150], [151, 161], [162, 163], [163, 166], [166, 167], [168, 176], [177, 183], [184, 191], [192, 200], [201, 204], [205, 213], [214, 222], [223, 233], [234, 235], [235, 238], [238, 239], [240, 248], [249, 257], [258, 266], [267, 269], [269, 270], [270, 272], [273, 275], [276, 280], [281, 286], [287, 292], [293, 298], [299, 303], [304, 309], [309, 310], [311, 314], [315, 319], [320, 323], [324, 330], [331, 333], [334, 342], [343, 344], [344, 345], [346, 350], [350, 351], [352, 354], [355, 359], [359, 360], [360, 361], [362, 369], [370, 372], [373, 376], [377, 380], [381, 390], [391, 394], [395, 399], [400, 402], [403, 408], [409, 414], [414, 415], [416, 426], [426, 427], [428, 430], [431, 435], [436, 439], [440, 443], [444, 448], [449, 454], [455, 459], [459, 460], [461, 464], [465, 471], [472, 482], [483, 486], [487, 488], [488, 494], [495, 506], [506, 507], [508, 512], [513, 520], [521, 525], [525, 526], [526, 532], [533, 544], [544, 545], [546, 548], [549, 553], [554, 556], [557, 568], [569, 571], [571, 573], [573, 579], [580, 583], [584, 593], [594, 596], [597, 603], [604, 608], [609, 614], [615, 619], [620, 624], [625, 629], [630, 635], [636, 637], [637, 640], [640, 644], [645, 646], [646, 651], [652, 657], [658, 661], [662, 666], [667, 672], [673, 677], [678, 682], [683, 688], [689, 691], [692, 693], [693, 698], [699, 703], [704, 705], [705, 706], [706, 707], [707, 708], [709, 711], [712, 716], [717, 720], [721, 725], [726, 731], [732, 743], [744, 751], [752, 755], [756, 762], [763, 764], [764, 767], [767, 771], [772, 774], [774, 775], None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "# Altro reminder: il nostro tokenizer inserisce dei \"None\" ovunque, tranne nella context window\n",
    "# La context window è formata da una lista di tuple\n",
    "# ogni tupla contiene (start_char_idx, end_char_idx) di ogni token\n",
    "print(small_validation_processed[\"offset_mapping\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b360a4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qui effettuiamo la conversione output - text\n",
    "n_largest = 20 # Numero massimo di logits da controllare\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "# Loopiamo sul dataset originale per prenderci l'answer originale\n",
    "for sample in small_validation_dataset:\n",
    "    sample_id = sample['id']\n",
    "    context = sample[\"context\"]\n",
    "    \n",
    "    # Inizializziamo gli score e le answer\n",
    "    best_score = float('-inf')\n",
    "    best_answer = None\n",
    "    \n",
    "    # Loopiamo nel mapping input samples per prenderci gli indici del dataset espanso corrispondenti\n",
    "    # Da qui calcoliamo la probabilità massima della risposta\n",
    "    for idx in sample_id2idxs[sample_id]:\n",
    "        start_logit = start_logits[idx]\n",
    "        end_logit = end_logits[idx]\n",
    "        offsets = small_validation_processed[idx][\"offset_mapping\"]\n",
    "        \n",
    "        start_indices = (-start_logit).argsort()\n",
    "        end_indices = (-end_logit).argsort()\n",
    "        \n",
    "        for start_idx in start_indices[:n_largest]:\n",
    "            for end_idx in end_indices[:n_largest]:\n",
    "                \n",
    "                # Caso 1: Siamo fuori dalla context window e skippiamo\n",
    "                if offsets[start_idx] is None or offsets[end_idx] is None:\n",
    "                    continue\n",
    "\n",
    "                # Caso 2: start >= end\n",
    "                if end_idx < start_idx:\n",
    "                    continue\n",
    "\n",
    "                # Caso 3: risposta troppo lunga\n",
    "                if end_idx - start_idx + 1 > max_answer_length:\n",
    "                    continue\n",
    "\n",
    "                # Calcolo dello score logaritmico dei logit.\n",
    "                # argmax(log((p_si, p_ej))) -> l_si + l_ej\n",
    "                score = start_logit[start_idx] + end_logit[end_idx]\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    # Ora troviamo la posizione relativa ai caratteri\n",
    "                    start_char = offsets[start_idx][0]\n",
    "                    end_char = offsets[end_idx][1]\n",
    "                    best_answer = context[start_char:end_char]\n",
    "    predicted_answers.append({\"id\":sample_id, \"prediction_text\": best_answer})\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9774bbef-d4b2-4686-bbb2-1dce4818889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       " 'answer_start': [177, 177, 177]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_validation_dataset[\"answers\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1b702fb-bfc7-4f27-b827-959183d1c412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "773e6003-33e2-45ee-955c-db7a37cec3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_answers = [{\"id\" : x[\"id\"], \"answers\": x[\"answers\"]} for x in small_validation_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3bcb5f0e-2e33-4f41-94d9-50ab99a41c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a558035a-7bcc-48bb-aaed-7b266d57464c",
   "metadata": {},
   "source": [
    "### Compute Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e9e19f0-6814-4aee-a429-617d00ae1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "240a539f-9893-4f20-8f0d-d4f757cdf648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(start_logits, end_logits, processed_dataset, orig_dataset):\n",
    "    sample_id2idxs = {}\n",
    "    for i, id_ in enumerate(processed_dataset[\"sample_id\"]):\n",
    "        if id_ not in sample_id2idxs:\n",
    "            sample_id2idxs[id_] = [i]\n",
    "        else:\n",
    "            sample_id2idxs[id_].append(i)\n",
    "\n",
    "    predicted_answers = []\n",
    "    # tqdm mostra solo una progress bar\n",
    "    for sample in tqdm(orig_dataset):\n",
    "        sample_id = sample['id']\n",
    "        context = sample[\"context\"]\n",
    "\n",
    "        best_score = float(\"-inf\")\n",
    "        best_answer = None\n",
    "        \n",
    "        for idx in sample_id2idxs[sample_id]:\n",
    "            start_logit = start_logits[idx]\n",
    "            end_logit = end_logits[idx]\n",
    "            # ATTENZIONE!! Qui, conviene usare prima [idx] e poi [\"offset_mapping\"] o ci mette un'eternità!\n",
    "            offsets = processed_dataset[idx][\"offset_mapping\"]\n",
    "            \n",
    "            start_indices = (-start_logit).argsort()\n",
    "            end_indices = (-end_logit).argsort()\n",
    "            \n",
    "            for start_idx in start_indices[:n_largest]:\n",
    "                for end_idx in end_indices[:n_largest]:\n",
    "                    \n",
    "                    # Caso 1: Siamo fuori dalla context window e skippiamo\n",
    "                    if offsets[start_idx] is None or offsets[end_idx] is None:\n",
    "                        continue\n",
    "    \n",
    "                    # Caso 2: start >= end\n",
    "                    if end_idx < start_idx:\n",
    "                        continue\n",
    "    \n",
    "                    # Caso 3: risposta troppo lunga\n",
    "                    if end_idx - start_idx + 1 > max_answer_length:\n",
    "                        continue\n",
    "    \n",
    "                    # Calcolo dello score logaritmico dei logit.\n",
    "                    # argmax(log((p_si, p_ej))) -> l_si + l_ej\n",
    "                    score = start_logit[start_idx] + end_logit[end_idx]\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        # Ora troviamo la posizione relativa ai caratteri\n",
    "                        start_char = offsets[start_idx][0]\n",
    "                        end_char = offsets[end_idx][1]\n",
    "                        best_answer = context[start_char:end_char]\n",
    "        \n",
    "        predicted_answers.append({\"id\":sample_id, \"prediction_text\": best_answer})\n",
    "\n",
    "    true_answers = [{\"id\" : x[\"id\"], \"answers\": x[\"answers\"]} for x in orig_dataset]\n",
    "\n",
    "    return metric.compute(predictions=predicted_answers, references=true_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a12780de-9912-4c45-81a7-65f9456cd509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 847.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 83.0, 'f1': 88.25000000000004}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(start_logits, end_logits, small_validation_processed, small_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc05e73-280f-434b-8d8a-8d8bbee8bf14",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e25348c-806d-4448-8e44-b29be8c1c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a84115d6-8db6-4c59-87d3-a3ff131bca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4cb5ca2a-ca82-40ba-9a64-d2dc1054b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    \"finetuned_squad\",\n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "76066a28-1848-4eb6-9fc7-c8c06b2cc766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=3.555673828125, metrics={'train_runtime': 82.2567, 'train_samples_per_second': 36.471, 'train_steps_per_second': 4.559, 'total_flos': 293969475072000.0, 'train_loss': 3.555673828125, 'epoch': 3.0})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset.shuffle(seed=42).select(range(1000)), #Non campionare se vuoi risultati buoni\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6373d189-901f-49ff-84bc-b88d0d8802a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_output = trainer.predict(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdf7c989-d8d1-4db0-ae59-88ba4b1835ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.trainer_utils.PredictionOutput"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0529a133-3202-4f48-8b1f-4c34764ea176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[-0.66015625,  0.45581055, -0.31225586, ..., -5.3320312 ,\n",
       "        -5.40625   , -5.3945312 ],\n",
       "       [-0.66064453,  0.4711914 , -0.27026367, ..., -5.3320312 ,\n",
       "        -5.40625   , -5.3945312 ],\n",
       "       [-0.6826172 ,  0.26464844, -1.9990234 , ..., -5.390625  ,\n",
       "        -5.359375  , -5.4101562 ],\n",
       "       ...,\n",
       "       [-0.7294922 , -0.484375  , -2.875     , ..., -5.0859375 ,\n",
       "        -5.4570312 , -5.4804688 ],\n",
       "       [-0.6977539 , -0.58935547, -1.0605469 , ..., -5.3632812 ,\n",
       "        -5.3515625 , -5.3515625 ],\n",
       "       [-0.71191406, -0.6845703 , -2.8613281 , ..., -5.0859375 ,\n",
       "        -5.46875   , -5.484375  ]], dtype=float32), array([[-0.15002441, -1.6738281 , -1.3349609 , ..., -5.3515625 ,\n",
       "        -5.3164062 , -5.234375  ],\n",
       "       [-0.15161133, -1.6660156 , -1.3017578 , ..., -5.3515625 ,\n",
       "        -5.3164062 , -5.2382812 ],\n",
       "       [-0.16015625, -1.0322266 , -2.8046875 , ..., -5.3164062 ,\n",
       "        -5.3203125 , -5.1953125 ],\n",
       "       ...,\n",
       "       [-0.15234375, -1.4248047 , -4.3203125 , ..., -5.1210938 ,\n",
       "        -5.2890625 , -5.1484375 ],\n",
       "       [-0.09875488, -2.015625  , -2.2519531 , ..., -5.34375   ,\n",
       "        -5.4179688 , -5.2734375 ],\n",
       "       [-0.14611816, -1.7138672 , -4.2304688 , ..., -5.1132812 ,\n",
       "        -5.2695312 , -5.1445312 ]], dtype=float32)), label_ids=None, metrics={'test_runtime': 78.9957, 'test_samples_per_second': 136.995, 'test_steps_per_second': 17.128})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c29e44a-f9b5-48f5-8a49-c96f879fa235",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, label_ids, metrics = trainer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "773fd34a-0929-4423-aa0b-d59192a7e750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.66015625,  0.45581055, -0.31225586, ..., -5.3320312 ,\n",
       "         -5.40625   , -5.3945312 ],\n",
       "        [-0.66064453,  0.4711914 , -0.27026367, ..., -5.3320312 ,\n",
       "         -5.40625   , -5.3945312 ],\n",
       "        [-0.6826172 ,  0.26464844, -1.9990234 , ..., -5.390625  ,\n",
       "         -5.359375  , -5.4101562 ],\n",
       "        ...,\n",
       "        [-0.7294922 , -0.484375  , -2.875     , ..., -5.0859375 ,\n",
       "         -5.4570312 , -5.4804688 ],\n",
       "        [-0.6977539 , -0.58935547, -1.0605469 , ..., -5.3632812 ,\n",
       "         -5.3515625 , -5.3515625 ],\n",
       "        [-0.71191406, -0.6845703 , -2.8613281 , ..., -5.0859375 ,\n",
       "         -5.46875   , -5.484375  ]], dtype=float32),\n",
       " array([[-0.15002441, -1.6738281 , -1.3349609 , ..., -5.3515625 ,\n",
       "         -5.3164062 , -5.234375  ],\n",
       "        [-0.15161133, -1.6660156 , -1.3017578 , ..., -5.3515625 ,\n",
       "         -5.3164062 , -5.2382812 ],\n",
       "        [-0.16015625, -1.0322266 , -2.8046875 , ..., -5.3164062 ,\n",
       "         -5.3203125 , -5.1953125 ],\n",
       "        ...,\n",
       "        [-0.15234375, -1.4248047 , -4.3203125 , ..., -5.1210938 ,\n",
       "         -5.2890625 , -5.1484375 ],\n",
       "        [-0.09875488, -2.015625  , -2.2519531 , ..., -5.34375   ,\n",
       "         -5.4179688 , -5.2734375 ],\n",
       "        [-0.14611816, -1.7138672 , -4.2304688 , ..., -5.1132812 ,\n",
       "         -5.2695312 , -5.1445312 ]], dtype=float32))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sappiamo che le predizioni sono start ed end logits.\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed6a22b5-9294-41e2-ad36-c69e0ffb86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits, end_logits = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4d24a55-f11a-4837-881b-e5b89911d94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10570/10570 [00:12<00:00, 837.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 13.907284768211921, 'f1': 23.692258097963602}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0083e5dc-672a-4de3-9502-fb9b55a6644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"my_squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde0896-d452-4adb-a8b2-d60e3e44d706",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d50ee021-e0bb-48ba-95f2-8ddfb9ecabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bb1415ac-ca1a-45ba-8c8a-4bce8e4a0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"my_squad\",\n",
    "    device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "130834ad-aa49-4c4c-bebb-ec22a9176540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.06326202303171158, 'start': 38, 'end': 46, 'answer': 'a carton'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"Today I went to the store to purchase a carton of milk.\"\n",
    "question = \"What did I buy?\"\n",
    "\n",
    "qa(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40683684-31f1-4128-af36-3e580f261e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd639f-c5c6-4809-845e-75123199b843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-env",
   "language": "python",
   "name": "transformer-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
