{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f08e02cb-bc06-4c34-b9c4-1b1ecb799830",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aab9eaf-9e21-486c-8b79-c4c5168e1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a9a9e3-718d-4e05-89a4-7499581f1abb",
   "metadata": {},
   "source": [
    "## Managing Dataset & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f291bc0-a07b-4deb-b57d-d2c22968be15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46267b70-38cc-4012-8372-384e44ea90c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"conll2003\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261d3253-21e9-4c3f-ac22-3e80c1dae819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437d46e2-87c7-4d02-a224-4156c5eaaf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4445849-9558-406d-819c-9c812c68984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'pos_tags': Sequence(feature=ClassLabel(names=['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB'], id=None), length=-1, id=None),\n",
       " 'chunk_tags': Sequence(feature=ClassLabel(names=['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP'], id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "619e0bbf-2dc5-4024-8f0e-62946a78aa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35bb378e-345b-4710-bddb-7cc94aab42fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24e9dec6-04f1-40d5-883c-e91e455e985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salviamo per dopo\n",
    "label_names = data[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9071c9cf-487d-4fbb-82d2-37066f1fb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bce0e0c-271e-4932-b4cf-62d92d5c0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usiamo Distilbert perchè si traina prima.\n",
    "# Usiamo il cased perchè abbiamo bisogno di distignuere i nomi e può aiutare\n",
    "checkpoint = \"distilbert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4da57d4-671a-4cc2-871c-d942b7b80072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23db876e-82b9-47e8-ade5-a98f7f0c8819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "La Named Entity Recognition usa il tokenizer in maniera differente. Al contrario del tokenizer classico che divide le parole\n",
    "in sottoparole, quando facciamo NER abbiamo bisogno di tenere le parole integre, altrimenti diventa difficile assegnar loro una label correttamente.\n",
    "Il dataset è già stato splittato in parole, per questo motivo, usiamo \"is_split_into_words=True\". \n",
    "ATTENZIONE: is_split_into_words non serve a creare i token basati su singole parole!!!!\n",
    "\"\"\"\n",
    "t = tokenizer(data[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73834ea4-35e6-4961-959d-ce297ce1bff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Il print di t sembra un dizionario. In realtà non lo è. E' un oggetto di tipo BatchEncoding\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad856b0-280a-409b-bf6e-de3b610395a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_MutableMapping__marker',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__ior__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__ror__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_encodings',\n",
       " '_n_sequences',\n",
       " 'char_to_token',\n",
       " 'char_to_word',\n",
       " 'clear',\n",
       " 'convert_to_tensors',\n",
       " 'copy',\n",
       " 'data',\n",
       " 'encodings',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'is_fast',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'n_sequences',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'sequence_ids',\n",
       " 'setdefault',\n",
       " 'to',\n",
       " 'token_to_chars',\n",
       " 'token_to_sequence',\n",
       " 'token_to_word',\n",
       " 'tokens',\n",
       " 'update',\n",
       " 'values',\n",
       " 'word_ids',\n",
       " 'word_to_chars',\n",
       " 'word_to_tokens',\n",
       " 'words']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vediamone gli attributi\n",
    "dir(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57ea78fb-4d7d-4fc2-8031-ce381561e8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vediamo i token generati:\n",
    "# Notiamo che la parola \"lamb\" è stata divisa in due sottoparole.\n",
    "t.tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7325635-0a91-44b8-b9fb-664a77754346",
   "metadata": {},
   "source": [
    "## Aligning Tokens to Targets\n",
    "\n",
    "Come possiamo fare per allineare i token ai targets? Abbiamo due casi specifici da affrontare per adesso:\n",
    "\n",
    "1) I token speciali come [CLS] e [SEP].\n",
    "2) Le parole spezzate come \"la\" e \"##mb\".\n",
    "\n",
    "Nel caso 1), ci servirà semplicmente utilizzare un valore da documentazione, -100, che servirà per ignorare totalmente i token. Questo avviene perchè la loss function creata per trainare il transformer è fatta appositamente per avere un gradiente pari a 0 in corrispondenza di -100.\n",
    "\n",
    "Nel caso 2), si procede ad ESPANDERE il target precedente: semplicemente basta copiare il valore precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0716049d-d1f8-4f67-8032-98dda9e300fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Ra', '##bino', '##vich', 'is', 'winding', 'up', 'his', 'term', 'as', 'ambassador', '.', '[SEP]']\n",
      "[None, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]\n"
     ]
    }
   ],
   "source": [
    "sample = data[\"train\"][100]\n",
    "tokens = sample[\"tokens\"]\n",
    "targets = sample[\"ner_tags\"]\n",
    "t = tokenizer(tokens, is_split_into_words=True)\n",
    "print(t.tokens())\n",
    "# I word ids sono molto utili. Si ripetono se la parola è spezzata e sono None per i token speciali\n",
    "print(t.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5895647e-6ea4-423d-8d5c-74401e4988d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56baa099-bea3-4c13-a750-950fce41bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMO TEST, SENZA INPUT\n",
    "def my_target_aligner(tokens, orig_targets):\n",
    "\n",
    "    target_cursor = 0\n",
    "    aligned_targets = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"[\"):\n",
    "            aligned_targets.append(-100)\n",
    "        elif token.startswith(\"##\"):\n",
    "            aligned_targets.append(aligned_targets[-1])\n",
    "        else:\n",
    "            aligned_targets.append(orig_targets[target_cursor])\n",
    "            target_cursor+=1\n",
    "\n",
    "    return aligned_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d2385ba-dd27-4de9-a685-9b764080bdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "print(my_target_aligner(t.tokens(), targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6aaaf79-4c8d-476f-a6e1-ab7e167a7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECONDO TEST CON INPUT DEL WORD ID E DELLA LABEL CONCATENATA\n",
    "# Begin2Inside necessario perchè a volte possono capitare già ID pari che si susseguono\n",
    "begin2inside = {\n",
    "  1: 2,\n",
    "  3: 4,\n",
    "  5: 6,\n",
    "  7: 8,\n",
    "}\n",
    "\n",
    "def target_aligner_with_wordids(ids, targets):\n",
    "\n",
    "    aligned_targets = []\n",
    "    last_word = None\n",
    "    \n",
    "    for wid in ids:\n",
    "        if wid is None:\n",
    "            # Qui abbiamo un token speciale da ignorare (id: None)\n",
    "            label = -100\n",
    "        elif last_word != wid:\n",
    "            label = targets[wid]\n",
    "        else:\n",
    "            label = targets[wid]\n",
    "            if label in begin2inside:\n",
    "                label = begin2inside[label]\n",
    "        aligned_targets.append(label)\n",
    "        last_word = wid\n",
    "            \n",
    "    return aligned_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "824fd5f3-77e9-466e-a7af-ae5d8e3a99dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "label_ids = target_aligner_with_wordids(t.word_ids(), targets)\n",
    "print(label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b55659-c282-44e2-a265-f08dac065377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 'B-PER', 'I-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_labels = [label_names[x] if x>=0 else None for x in label_ids]\n",
    "aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a404fc3-b40c-4a8b-b5ec-ea8e3c25d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: None\n",
      "Ra: B-PER\n",
      "##bino: I-PER\n",
      "##vich: I-PER\n",
      "is: O\n",
      "winding: O\n",
      "up: O\n",
      "his: O\n",
      "term: O\n",
      "as: O\n",
      "ambassador: O\n",
      ".: O\n",
      "[SEP]: None\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(t.tokens(), aligned_labels):\n",
    "    print(f\"{x}: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15b419f7-41a2-4dca-bc4f-6831d5bd6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    tokenized_inputs = tokenizer(batch[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels_batch = batch[\"ner_tags\"] # Original targets\n",
    "    aligned_batch_labels = []\n",
    "    for i, labels in enumerate(labels_batch):\n",
    "        word_id = tokenized_inputs.word_ids(i)\n",
    "        aligned_labels = target_aligner_with_wordids(word_id, labels)\n",
    "        aligned_batch_labels.append(aligned_labels)\n",
    "\n",
    "    # Ricordiamo: il nostro target DEVE essere salvato in una colonna chiamata \"labels\"\n",
    "    tokenized_inputs[\"labels\"] = aligned_batch_labels\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23c9799b-a374-4368-844e-b78e9d1fe2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Poi puliamo il risultato eliminando queste colonne\n",
    "data[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb7a1e2c-17fe-4d04-9243-7a806e20cbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████| 3250/3250 [00:00<00:00, 11193.71 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = data.map(tokenize_fn, batched=True, remove_columns=data[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a87e8d2-9172-4ac8-85d8-63854a470789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101,\n",
       "   7270,\n",
       "   22961,\n",
       "   1528,\n",
       "   1840,\n",
       "   1106,\n",
       "   21423,\n",
       "   1418,\n",
       "   2495,\n",
       "   12913,\n",
       "   119,\n",
       "   102],\n",
       "  [101, 1943, 14428, 102],\n",
       "  [101, 26660, 13329, 12649, 15928, 1820, 118, 4775, 118, 1659, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       " 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100],\n",
       "  [-100, 1, 2, -100],\n",
       "  [-100, 5, 6, 6, 6, 0, 0, 0, 0, 0, -100]]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578ba06-d7b7-4cf8-8a69-b8f45ed18d71",
   "metadata": {},
   "source": [
    "## Data Collator\n",
    "\n",
    "I modelli sono equipaggiati di default con un Data Collator. Questo si occupa di rendere il dato uniforme, creando il giusto padding\n",
    "e trasformando gli input in tensori automaticamente. Questo viene fatto in automatico dal trainer.\n",
    "\n",
    "Per i task di \"Token Classification\" come NER e POS, il data collator deve essere creato a mano ed inserito. Non è niente di eccezionale, la scrittura è spesso ridondante (è necessario inserire il tokenizer che viene poi effettivamente re-inserito nel trainer).\n",
    "\n",
    "Il collator effettua le operazioni sui batch. Possiamo vedere un esempio dopo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c89e3e50-4ab5-40c5-bd90-5a9544054f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "444fa05f-f979-41f1-a866-54471215b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator =  DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "523fa4bc-dfb8-4fdc-81e6-8ea6cabad89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101,\n",
       "   7270,\n",
       "   22961,\n",
       "   1528,\n",
       "   1840,\n",
       "   1106,\n",
       "   21423,\n",
       "   1418,\n",
       "   2495,\n",
       "   12913,\n",
       "   119,\n",
       "   102],\n",
       "  [101, 1943, 14428, 102]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1]],\n",
       " 'labels': [[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100], [-100, 1, 2, -100]]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se usiamo questa modalitò, otteniamo un dizionario che comprende liste di liste. Il collator non le accetta\n",
    "tokenized_datasets[\"train\"][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7f7d51c-d2f6-44da-bf08-7559fa1df326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [101,\n",
       "   7270,\n",
       "   22961,\n",
       "   1528,\n",
       "   1840,\n",
       "   1106,\n",
       "   21423,\n",
       "   1418,\n",
       "   2495,\n",
       "   12913,\n",
       "   119,\n",
       "   102],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]},\n",
       " {'input_ids': [101, 1943, 14428, 102],\n",
       "  'attention_mask': [1, 1, 1, 1],\n",
       "  'labels': [-100, 1, 2, -100]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Per ottenere invece la lista di dizionari, dobbiamo esplicitamente ciclare nel dizionario con list comprehension\n",
    "[tokenized_datasets[\"train\"][i] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6073b01d-8290-44da-905a-2e0e79d8f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notiamo effettivamente come il padding viene applicato col -100\n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77de7f-ae96-4f11-a7bf-8d1de197fe4b",
   "metadata": {},
   "source": [
    "## Metrics \n",
    "\n",
    "Per quanto riguarda le metriche per valutare il training, ci affidiamo alla metrica \"seqeval\". Questa metrica si occupa di calcolare effettivamente il valore di precisione delle predizioni, tenendo in conto che abbiamo delle sostanziali differenze rispetto alla normale text-classification.\n",
    "\n",
    "In primo luogo, abbiamo dei tag. Questi tag seguono il formato BIO (Begin, Internal, Outer) e, dato che la metrica è specifica, classi al di fuori di queste non vengono considerate. Per questo motivo abbiamo bisogno di risalire al tag preciso per fare i calcoli. Questo ci serve per avere un'accuratezza anche in ciò che prediciamo, cercando di discriminare quali tag vengano effettivamente predetti meglio.\n",
    "\n",
    "In secondo luogo, abbiamo una struttura differente degli output del modello: prima avevamo un set di label (dimensione BatchSize) confrontato con il set di logits predetti (BatchSize x NClasses). Ora, invece, abbiamo una terza dimensione che si unisce ad entrambi gli output, che è la lunghezza dell'input stesso. Quindi avremo BatchSize x Nwords da comparare a BatchSize x NClasses x NWords.\n",
    "\n",
    "Inoltre, abbiamo il -100 che è l'output ignorato. Va eliminato per evitare di inquinare le predizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c2a0d22-6de8-4abe-920d-581a557a3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "# !pip install seqeval [necessario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33c686d8-d057-4cf0-9a04-692cdbd988bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14c2d4f2-7016-49ef-aecd-bbe1e8ba719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test1 per errore\n",
    "# metric.compute(predictions=[0,0,0], references=[0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8dbb5ab-37c3-4c15-acaa-e534c95ef071",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: 0 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: 1 seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\emili\\Desktop\\transformers_course\\transformers-env\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test2 per errore -> si aspetta i tag veri. Si aspetta stringhe.\n",
    "metric.compute(predictions=[[\"0\",\"0\",\"0\"]], references=[[\"0\",\"1\",\"0\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "075d9c36-9560-41b6-b469-b528b4ade962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ORG': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1},\n",
       " 'overall_precision': 0.0,\n",
       " 'overall_recall': 0.0,\n",
       " 'overall_f1': 0.0,\n",
       " 'overall_accuracy': 0.75}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test3 ok\n",
    "# NB: siccome la libreria sa quello che fa, trovare un \"I-ORG\" corretto nelle predictions senza il precedente B-ORG viene considerato errore\n",
    "metric.compute(predictions=[[\"O\",\"O\",\"I-ORG\", \"O\"]], references=[[\"O\",\"B-ORG\",\"I-ORG\", \"O\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b8abbd8-b65d-4b73-ba9c-9161598036e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    \n",
    "    logits, labels = logits_and_labels\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # rimuoviamo tutti i -100\n",
    "    # convertiamo i label id in nomi usando la mappa sopa\n",
    "    str_labels = [[label_names[t] for t in label if t != -100] for label in labels]\n",
    "\n",
    "    # Stesso per le predizioni, ma con un qualcosa di diverso: controlliamo sulla label se è -100\n",
    "    str_preds = [[label_names[p] for p, t in zip(pred, targ) if t != -100] for pred, targ in zip(preds, labels)]\n",
    "\n",
    "    # Sia str_preds che str_labels ora sono liste di liste che hanno al loro interno i tag del NER\n",
    "    the_metrics = metric.compute(predictions=str_preds, references=str_labels)\n",
    "\n",
    "    return {\n",
    "        'precision': the_metrics['overall_precision'],\n",
    "        'recall': the_metrics['overall_recall'],\n",
    "        'f1': the_metrics['overall_f1'],\n",
    "        'accuracy': the_metrics['overall_accuracy'],\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f5c7d-7157-4359-be3c-235812b9f517",
   "metadata": {},
   "source": [
    "## Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e13af00-9f36-4352-af83-51b659cb9922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "184cca59-747f-40c0-868f-f565c2ee0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodo alternativo per iniettare le labels\n",
    "id2label = {k:v for k, v in enumerate(label_names)}\n",
    "label2id = {v:k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4ff940d-590e-4a41-aeb0-a473213868a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ede83af-0a5c-4a8e-9cc8-eea3836e4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-finetuned-ner\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01 #L2 Regularization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b562d976-1e7e-49aa-a247-724135680ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '8', 'tokens': ['Fischler', 'proposed', 'EU-wide', 'measures', 'after', 'reports', 'from', 'Britain', 'and', 'France', 'that', 'under', 'laboratory', 'conditions', 'sheep', 'could', 'contract', 'Bovine', 'Spongiform', 'Encephalopathy', '(', 'BSE', ')', '--', 'mad', 'cow', 'disease', '.'], 'pos_tags': [17, 40, 22, 42, 15, 24, 15, 22, 10, 22, 43, 15, 21, 24, 21, 20, 37, 22, 22, 22, 4, 22, 5, 8, 16, 21, 21, 7], 'chunk_tags': [11, 12, 12, 21, 13, 11, 13, 11, 12, 12, 11, 13, 11, 11, 12, 21, 22, 11, 12, 12, 0, 11, 0, 0, 11, 12, 12, 0], 'ner_tags': [1, 0, 7, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# Esempio dato con ner tag 8 esistente\n",
    "print(data[\"train\"][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcfa775f-3f72-4bb6-b67c-400e0cc98652",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13590559-3e67-4b5a-b9a7-f9d9424e8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5268' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5268/5268 06:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>0.879221</td>\n",
       "      <td>0.911478</td>\n",
       "      <td>0.895059</td>\n",
       "      <td>0.976247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.074190</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.928644</td>\n",
       "      <td>0.918442</td>\n",
       "      <td>0.981751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>0.071450</td>\n",
       "      <td>0.915748</td>\n",
       "      <td>0.936553</td>\n",
       "      <td>0.926034</td>\n",
       "      <td>0.983105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5268, training_loss=0.07935355708919517, metrics={'train_runtime': 377.5629, 'train_samples_per_second': 111.566, 'train_steps_per_second': 13.953, 'total_flos': 460431563935266.0, 'train_loss': 0.07935355708919517, 'epoch': 3.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c780b6c9-de7b-43e0-9924-65d2c61aaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af1ed256-d777-4e2a-ba01-5b360e769eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"token-classification\", model=\"distilbert-finetuned-ner/checkpoint-5268/\", aggregation_strategy=\"simple\", \n",
    "               device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04178726-5e0b-404e-ac3d-c3421bb154e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99927205,\n",
       "  'word': 'Bill Gates',\n",
       "  'start': 0,\n",
       "  'end': 10},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9992894,\n",
       "  'word': 'Microsoft',\n",
       "  'start': 26,\n",
       "  'end': 35},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99927443,\n",
       "  'word': 'Seattle',\n",
       "  'start': 39,\n",
       "  'end': 46},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9989988,\n",
       "  'word': 'Washington',\n",
       "  'start': 48,\n",
       "  'end': 58}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Bill Gates was the CEO of Microsoft in Seattle, Washington\"\n",
    "ner(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be650c0f-31c9-4b20-9aeb-45511babc38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer-env",
   "language": "python",
   "name": "transformer-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
